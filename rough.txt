listen i have a long query and your user input is limited. So, i will give in parts summarize and remember each and every thing so we can discuss the project:
first let me give you the structure of my project.:
MathAI/
├── README.md
├── .env                          # API keys (GEMINI_API_KEY, TAVILY_API_KEY)
├── .gitignore
├── requirements.txt              # Backend Python dependencies
├── package.json                  # Frontend npm dependencies
│
├── data/
│   ├── math_knowledge_base.json  # From Notebook 1
│   ├── rag_config.json           # From Notebook 2
│   ├── mcp_config.json           # From Notebook 3
│   └── feedback.db               # SQLite database
│
├── notebooks/                    # Keep your original notebooks for reference
│   ├── 01_data_preparation.ipynb
│   ├── 02_rag_qdrant.ipynb
│   ├── 03_mcp_websearch.ipynb
│   ├── 04_routing_agent.ipynb
│   └── 05_gradio_ui.ipynb
│
├── backend/
│   ├── __init__.py
│   ├── main.py                   # FastAPI application entry point
│   │
│   ├── api/
│   │   ├── __init__.py
│   │   ├── routes.py             # All API endpoints
│   │   └── websocket.py          # WebSocket for real-time chat (optional)
│   │
│   ├── core/
│   │   ├── __init__.py
│   │   ├── config.py             # Configuration & environment variables
│   │   ├── database.py           # SQLite connection management
│   │   └── schemas.py            # Pydantic models for request/response
│   │
│   ├── services/
│   │   ├── __init__.py
│   │   ├── embeddings.py         # SentenceTransformer wrapper
│   │   ├── rag_engine.py         # Qdrant vector search logic
│   │   ├── web_search.py         # Tavily MCP web search
│   │   ├── gemini_agent.py       # Gemini API integration
│   │   ├── guardrails.py         # Input/output validation
│   │   └── routing.py            # Decision logic (KB vs Web)
│   │
│   └── utils/
│       ├── __init__.py
│       └── helpers.py            # Utility functions
│
├── frontend/
│   ├── public/
│   │   ├── index.html
│   │   └── favicon.ico
│   │
│   ├── src/
│   │   ├── components/
│   │   │   ├── ChatWindow.jsx    # Main chat interface
│   │   │   ├── Sidebar.jsx       # Navigation sidebar
│   │   │   ├── MessageBubble.jsx # Individual message component
│   │   │   ├── InputArea.jsx     # Message input box
│   │   │   ├── FeedbackModal.jsx # Feedback collection
│   │   │   ├── AnalyticsView.jsx # Statistics dashboard
│   │   │   ├── AboutView.jsx     # About page
│   │   │   └── SettingsPanel.jsx # Settings modal
│   │   │
│   │   ├── hooks/
│   │   │   └── useChat.js        # Custom hook for chat logic
│   │   │
│   │   ├── services/
│   │   │   └── api.js            # Axios/fetch API client
│   │   │
│   │   ├── styles/
│   │   │   ├── globals.css
│   │   │   └── components.css
│   │   │
│   │   ├── App.jsx
│   │   └── index.js
│   │
│   ├── package.json
│   └── vite.config.js            # Using Vite for faster development
│
├── scripts/
│   ├── init_db.py                # Initialize database & tables
│   ├── load_data.py              # Load knowledge base into Qdrant
│   ├── dev.sh                    # Start backend + frontend concurrently
│   └── test_api.py               # API testing script
│
└── docker/
    ├── Dockerfile.backend
    ├── Dockerfile.frontend
    └── docker-compose.yml

now i am giving you the files code with name at top:
1. __init__.py
2. backend/api/router.py:
"""
API Routes for MathAI
"""
from fastapi import APIRouter, Request, HTTPException, Depends
from typing import Optional
import logging
from datetime import datetime
import uuid

from core.schemas import (
    ChatRequest, ChatResponse,
    FeedbackRequest, FeedbackResponse, FeedbackStats,
    SearchRequest, SearchResponse,
    AnalyticsRequest, AnalyticsResponse,
    HealthResponse
)
from core.database import db
from services.routing import RoutingService
from services.guardrails import guardrails
from services.web_search import web_search
from services.gemini_agent import gemini_agent

logger = logging.getLogger(__name__)

router = APIRouter()


def get_routing_service(request: Request) -> RoutingService:
    """Dependency to get routing service from request state"""
    return RoutingService(
        rag_engine=request.state.rag_engine,
        web_search=web_search,
        gemini_agent=gemini_agent,
        guardrails=guardrails
    )


# ========== Health & Status ==========

@router.get("/health", response_model=HealthResponse)
async def health_check(request: Request):
    """Health check endpoint"""
    services_status = {
        "rag_engine": request.state.rag_engine is not None,
        "embedding_service": request.state.embedding_service is not None,
        "gemini": gemini_agent.model is not None,
        "web_search": web_search.client is not None,
        "database": True  # Database is always available (SQLite)
    }
    
    return HealthResponse(
        status="healthy" if all(services_status.values()) else "degraded",
        version="1.0.0",
        timestamp=datetime.now(),
        services=services_status
    )


# ========== Chat Endpoints ==========

@router.post("/chat", response_model=ChatResponse)
async def chat(
    request: ChatRequest,
    routing_service: RoutingService = Depends(get_routing_service)
):
    """
    Main chat endpoint - process user query and return solution
    """
    try:
        # Generate session ID if not provided
        session_id = request.session_id or str(uuid.uuid4())
        
        # Log user message
        db.save_message(
            session_id=session_id,
            role="user",
            content=request.message,
            metadata={"use_feedback_learning": request.use_feedback_learning}
        )
        
        # Log analytics event
        db.log_event(
            event_type="query",
            event_data={"query_length": len(request.message)},
            session_id=session_id
        )
        
        # Process query
        response = await routing_service.process_query(request)
        
        # Log assistant message
        if response.success:
            db.save_message(
                session_id=session_id,
                role="assistant",
                content=response.solution,
                metadata={
                    "source": response.routing.source.value if response.routing else "unknown",
                    "confidence": response.routing.confidence if response.routing else 0.0
                }
            )
        
        return response
        
    except Exception as e:
        logger.error(f"Chat endpoint error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/chat/history")
async def get_chat_history(
    session_id: str,
    limit: int = 50
):
    """Get chat history for a session"""
    try:
        history = db.get_chat_history(session_id, limit)
        return {
            "success": True,
            "session_id": session_id,
            "messages": history,
            "count": len(history)
        }
    except Exception as e:
        logger.error(f"Failed to get chat history: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ========== Feedback Endpoints ==========

@router.post("/feedback", response_model=FeedbackResponse)
async def submit_feedback(feedback: FeedbackRequest):
    """Submit feedback for a solution"""
    try:
        feedback_id = db.save_feedback(
            query=feedback.query,
            solution=feedback.solution,
            rating=feedback.rating,
            comment=feedback.comment,
            improved_solution=feedback.improved_solution,
            model_used="gemini-pro",
            source="unknown",  # Could be enhanced to track source
            confidence=None
        )
        
        # Log analytics event
        db.log_event(
            event_type="feedback_submitted",
            event_data={
                "rating": feedback.rating,
                "has_comment": feedback.comment is not None,
                "has_improvement": feedback.improved_solution is not None
            }
        )
        
        return FeedbackResponse(
            success=True,
            message="Feedback submitted successfully",
            feedback_id=feedback_id
        )
        
    except Exception as e:
        logger.error(f"Failed to submit feedback: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/feedback/stats", response_model=FeedbackStats)
async def get_feedback_stats():
    """Get feedback statistics"""
    try:
        stats = db.get_feedback_stats()
        return FeedbackStats(**stats)
    except Exception as e:
        logger.error(f"Failed to get feedback stats: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/feedback/positive")
async def get_positive_feedback(min_rating: int = 4):
    """Get positive feedback for learning"""
    try:
        feedback = db.get_positive_feedback(min_rating)
        return {
            "success": True,
            "count": len(feedback),
            "feedback": feedback
        }
    except Exception as e:
        logger.error(f"Failed to get positive feedback: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ========== Knowledge Base Endpoints ==========

@router.post("/kb/search", response_model=SearchResponse)
async def search_knowledge_base(
    search: SearchRequest,
    request: Request
):
    """Search knowledge base directly"""
    try:
        rag_engine = request.state.rag_engine
        if not rag_engine:
            raise HTTPException(status_code=503, detail="RAG engine not available")
        
        result = rag_engine.search(
            query=search.query,
            top_k=search.top_k,
            score_threshold=search.score_threshold
        )
        
        return result
        
    except Exception as e:
        logger.error(f"KB search failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/kb/stats")
async def get_kb_stats(request: Request):
    """Get knowledge base statistics"""
    try:
        rag_engine = request.state.rag_engine
        if not rag_engine:
            raise HTTPException(status_code=503, detail="RAG engine not available")
        
        return {
            "success": True,
            "total_problems": len(rag_engine.knowledge_base),
            "collection_name": rag_engine.collection_name,
            "topics": list(set(item['topic'] for item in rag_engine.knowledge_base)),
            "difficulties": list(set(item['difficulty'] for item in rag_engine.knowledge_base))
        }
        
    except Exception as e:
        logger.error(f"Failed to get KB stats: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ========== Web Search Endpoint ==========

@router.post("/web/search")
async def perform_web_search(search: SearchRequest):
    """Perform web search directly"""
    try:
        result = web_search.search_with_retry(search.query)
        return result
    except Exception as e:
        logger.error(f"Web search failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ========== Analytics Endpoints ==========

@router.get("/analytics", response_model=AnalyticsResponse)
async def get_analytics(days: int = 7):
    """Get analytics for last N days"""
    try:
        analytics = db.get_analytics(days)
        feedback_stats = db.get_feedback_stats()
        
        return AnalyticsResponse(
            period_days=days,
            total_queries=analytics['total_queries'],
            total_feedback=feedback_stats['total_feedback'],
            average_rating=feedback_stats['average_rating'],
            rating_distribution=feedback_stats['rating_distribution'],
            events=analytics['events'],
            top_topics=[]  # Could be enhanced
        )
        
    except Exception as e:
        logger.error(f"Failed to get analytics: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ========== Utility Endpoints ==========

@router.post("/improve")
async def improve_solution(
    query: str,
    solution: str,
    feedback: str,
    improved_suggestion: Optional[str] = None
):
    """Generate improved solution based on feedback"""
    try:
        result = gemini_agent.improve_solution(
            original_query=query,
            original_solution=solution,
            feedback=feedback,
            improved_suggestion=improved_suggestion
        )
        
        if result['success']:
            return {
                "success": True,
                "improved_solution": result['solution']
            }
        else:
            raise HTTPException(status_code=500, detail=result['error'])
            
    except Exception as e:
        logger.error(f"Failed to improve solution: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/")
async def api_root():
    """API root endpoint"""
    return {
        "name": "MathAI API",
        "version": "1.0.0",
        "endpoints": {
            "health": "/api/health",
            "chat": "/api/chat",
            "feedback": "/api/feedback",
            "search": "/api/kb/search",
            "analytics": "/api/analytics",
            "docs": "/docs"
        }
    }
3. websocket.py:
4. backend/core/__init__.py
5. backend/core/config.py
"""
Configuration management using Pydantic Settings
"""
from pydantic_settings import BaseSettings
from typing import List
import os


class Settings(BaseSettings):
    """Application settings from environment variables"""
    
    # API Keys
    GEMINI_API_KEY: str
    TAVILY_API_KEY: str
    
    # Database
    DATABASE_URL: str = "sqlite:///./data/feedback.db"
    
    # Qdrant
    QDRANT_MEMORY: bool = True
    QDRANT_PATH: str = "./data/qdrant_storage"
    QDRANT_COLLECTION: str = "math_problems"
    
    # Embeddings
    EMBEDDING_MODEL: str = "all-MiniLM-L6-v2"
    EMBEDDING_DIM: int = 384
    
    # RAG Configuration
    KB_CONFIDENCE_THRESHOLD: float = 0.5
    KB_TOP_K: int = 3
    WEB_SEARCH_MAX_RESULTS: int = 3
    
    # Server
    BACKEND_HOST: str = "0.0.0.0"
    BACKEND_PORT: int = 8000
    FRONTEND_PORT: int = 5173
    
    # CORS
    CORS_ORIGINS: List[str] = ["http://localhost:5173", "http://localhost:3000"]
    
    # Logging
    LOG_LEVEL: str = "INFO"
    
    # Security
    SECRET_KEY: str = "your-secret-key-change-in-production"
    
    # Guardrails
    ENABLE_GUARDRAILS: bool = True
    MAX_QUERY_LENGTH: int = 500
    
    # Feedback
    ENABLE_FEEDBACK_LEARNING: bool = True
    MIN_POSITIVE_RATING: int = 4
    
    # Rate Limiting
    RATE_LIMIT_ENABLED: bool = True
    RATE_LIMIT_PER_MINUTE: int = 30
    
    # Development
    DEBUG_MODE: bool = False
    SHOW_STACK_TRACES: bool = False
    
    class Config:
        env_file = ".env"
        case_sensitive = True


# Global settings instance
settings = Settings()























































6. backend/core/database.py:
"""
Database management using SQLite
"""
import sqlite3
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
import logging

from core.config import settings

logger = logging.getLogger(__name__)


class Database:
    """SQLite database manager"""
    
    def __init__(self, db_path: str = None):
        if db_path is None:
            db_path = settings.DATABASE_URL.replace("sqlite:///", "")
        
        # Ensure data directory exists
        Path(db_path).parent.mkdir(parents=True, exist_ok=True)
        
        self.db_path = db_path
        self._init_tables()
    
    def _get_connection(self):
        """Get database connection"""
        return sqlite3.connect(self.db_path)
    
    def _init_tables(self):
        """Initialize database tables"""
        conn = self._get_connection()
        cursor = conn.cursor()
        
        # Feedback table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS feedback (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                query TEXT NOT NULL,
                solution TEXT NOT NULL,
                rating INTEGER NOT NULL,
                comment TEXT,
                improved_solution TEXT,
                routing_source TEXT,
                session_id TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Chat history table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS chat_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT NOT NULL,
                role TEXT NOT NULL,
                content TEXT NOT NULL,
                routing_source TEXT,
                timestamp TEXT NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Analytics events table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS analytics_events (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                event_type TEXT NOT NULL,
                event_data TEXT,
                timestamp TEXT NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Create indexes
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_feedback_rating ON feedback(rating)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_feedback_timestamp ON feedback(timestamp)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_chat_session ON chat_history(session_id)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_analytics_type ON analytics_events(event_type)')
        
        conn.commit()
        conn.close()
        logger.info("✅ Database tables initialized")
    
    # ========== Feedback Methods ==========
    
    def save_feedback(
        self,
        query: str,
        solution: str,
        rating: int,
        comment: str = None,
        improved_solution: str = None,
        routing_source: str = None,
        session_id: str = None
    ) -> int:
        """Save user feedback"""
        conn = self._get_connection()
        cursor = conn.cursor()
        
        timestamp = datetime.now().isoformat()
        
        cursor.execute('''
            INSERT INTO feedback (
                timestamp, query, solution, rating, comment, 
                improved_solution, routing_source, session_id
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (timestamp, query, solution, rating, comment, 
              improved_solution, routing_source, session_id))
        
        feedback_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        logger.info(f"✅ Feedback saved (ID: {feedback_id}, Rating: {rating})")
        return feedback_id
    
    def get_feedback_stats(self) -> Dict:
        """Get feedback statistics"""
        conn = self._get_connection()
        cursor = conn.cursor()
        
        # Total feedback and average rating
        cursor.execute('''
            SELECT COUNT(*), AVG(rating) FROM feedback
        ''')
        total, avg_rating = cursor.fetchone()
        
        # Rating distribution
        cursor.execute('''
            SELECT rating, COUNT(*) FROM feedback 
            GROUP BY rating 
            ORDER BY rating DESC
        ''')
        distribution = {str(row[0]): row[1] for row in cursor.fetchall()}
        
        conn.close()
        
        return {
            'total_feedback': total or 0,
            'average_rating': round(avg_rating, 2) if avg_rating else 0.0,
            'rating_distribution': distribution,
            'total_queries': total or 0
        }
    
    def get_positive_feedback(self, min_rating: int = 4) -> List[Dict]:
        """Get positive feedback for learning"""
        conn = self._get_connection()
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT query, solution, improved_solution, rating, comment
            FROM feedback
            WHERE rating >= ?
            ORDER BY rating DESC, created_at DESC
            LIMIT 50
        ''', (min_rating,))
        
        results = []
        for row in cursor.fetchall():
            results.append({
                'query': row[0],
                'solution': row[1],
                'improved_solution': row[2],
                'rating': row[3],
                'comment': row[4]
            })
        
        conn.close()
        return results
    
    # ========== Chat History Methods ==========
    
    def save_chat_message(
        self,
        session_id: str,
        role: str,
        content: str,
        routing_source: str = None
    ):
        """Save chat message to history"""
        conn = self._get_connection()
        cursor = conn.cursor()
        
        timestamp = datetime.now().isoformat()
        
        cursor.execute('''
            INSERT INTO chat_history (session_id, role, content, routing_source, timestamp)
            VALUES (?, ?, ?, ?, ?)
        ''', (session_id, role, content, routing_source, timestamp))
        
        conn.commit()
        conn.close()
    
    def get_chat_history(self, session_id: str, limit: int = 50) -> List[Dict]:
        """Get chat history for a session"""
        conn = self._get_connection()
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT role, content, routing_source, timestamp
            FROM chat_history
            WHERE session_id = ?
            ORDER BY created_at DESC
            LIMIT ?
        ''', (session_id, limit))
        
        results = []
        for row in cursor.fetchall():
            results.append({
                'role': row[0],
                'content': row[1],
                'routing_source': row[2],
                'timestamp': row[3]
            })
        
        conn.close()
        return list(reversed(results))
    
    # ========== Analytics Methods ==========
    
    def log_event(self, event_type: str, event_data: str = None):
        """Log analytics event"""
        conn = self._get_connection()
        cursor = conn.cursor()
        
        timestamp = datetime.now().isoformat()
        
        cursor.execute('''
            INSERT INTO analytics_events (event_type, event_data, timestamp)
            VALUES (?, ?, ?)
        ''', (event_type, event_data, timestamp))
        
        conn.commit()
        conn.close()
    
    def get_analytics(self, days: int = 7) -> Dict:
        """Get analytics for specified period"""
        conn = self._get_connection()
        cursor = conn.cursor()
        
        # Get date range
        from datetime import timedelta
        start_date = (datetime.now() - timedelta(days=days)).isoformat()
        
        # Total queries
        cursor.execute('''
            SELECT COUNT(*) FROM analytics_events
            WHERE event_type = 'query' AND timestamp >= ?
        ''', (start_date,))
        total_queries = cursor.fetchone()[0]
        
        # Get feedback stats for period
        cursor.execute('''
            SELECT COUNT(*), AVG(rating) FROM feedback
            WHERE timestamp >= ?
        ''', (start_date,))
        total_feedback, avg_rating = cursor.fetchone()
        
        # Rating distribution
        cursor.execute('''
            SELECT rating, COUNT(*) FROM feedback
            WHERE timestamp >= ?
            GROUP BY rating
        ''', (start_date,))
        distribution = {str(row[0]): row[1] for row in cursor.fetchall()}
        
        # Recent events
        cursor.execute('''
            SELECT event_type, event_data, timestamp
            FROM analytics_events
            WHERE timestamp >= ?
            ORDER BY created_at DESC
            LIMIT 100
        ''', (start_date,))
        
        events = []
        for row in cursor.fetchall():
            events.append({
                'type': row[0],
                'data': row[1],
                'timestamp': row[2]
            })
        
        conn.close()
        
        return {
            'period_days': days,
            'total_queries': total_queries,
            'total_feedback': total_feedback or 0,
            'average_rating': round(avg_rating, 2) if avg_rating else 0.0,
            'rating_distribution': distribution,
            'events': events
        }


# Global database instance
_db_instance = None


def init_db() -> Database:
    """Initialize global database instance"""
    global _db_instance
    if _db_instance is None:
        _db_instance = Database()
    return _db_instance


def get_db() -> Database:
    """Get database instance"""
    if _db_instance is None:
        return init_db()
    return _db_instance

7. backend/core/schema.py:
"""
Pydantic schemas for request/response validation
"""
from pydantic import BaseModel, Field
from typing import Optional, Dict, Any, List
from datetime import datetime
from enum import Enum


# ========== Enums ==========

class SourceType(str, Enum):
    """Source of information"""
    KNOWLEDGE_BASE = "knowledge_base"
    WEB_SEARCH = "web_search"
    DIRECT_LLM = "direct_llm"


# ========== Chat Schemas ==========

class ChatRequest(BaseModel):
    """Request for chat endpoint"""
    message: str = Field(..., min_length=1, max_length=2000)
    session_id: Optional[str] = None
    use_feedback_learning: bool = True


class RoutingDecision(BaseModel):
    """Routing decision information"""
    use_kb: bool
    confidence: float
    reason: str
    source: SourceType


class ChatResponse(BaseModel):
    """Response from chat endpoint"""
    success: bool
    message: str
    query: str
    solution: Optional[str] = None
    routing: Optional[RoutingDecision] = None
    metadata: Optional[Dict[str, Any]] = None
    blocked: bool = False
    error: Optional[str] = None


# ========== Feedback Schemas ==========

class FeedbackRequest(BaseModel):
    """Request for submitting feedback"""
    query: str
    solution: str
    rating: int = Field(..., ge=1, le=5)
    comment: Optional[str] = None
    improved_solution: Optional[str] = None


class FeedbackResponse(BaseModel):
    """Response after submitting feedback"""
    success: bool
    message: str
    feedback_id: Optional[int] = None


class FeedbackStats(BaseModel):
    """Feedback statistics"""
    total_feedback: int
    average_rating: float
    rating_distribution: Dict[str, int]
    total_queries: int = 0


# ========== Search Schemas ==========

class SearchRequest(BaseModel):
    """Request for knowledge base search"""
    query: str
    top_k: int = 3
    score_threshold: float = 0.5


class SearchResult(BaseModel):
    """Single search result"""
    question: str
    answer: str
    topic: str
    difficulty: str
    score: float


class SearchResponse(BaseModel):
    """Response from search endpoint"""
    success: bool
    query: str
    results: List[SearchResult]
    count: int


# ========== Web Search Schemas ==========

class WebSearchResult(BaseModel):
    """Web search result"""
    title: str
    url: str
    content: str
    score: float = 0.0


class WebSearchResponse(BaseModel):
    """Response from web search"""
    success: bool
    query: str
    results: List[WebSearchResult]
    error: Optional[str] = None


# ========== Analytics Schemas ==========

class AnalyticsRequest(BaseModel):
    """Request for analytics"""
    days: int = 7
    event_type: Optional[str] = None


class AnalyticsResponse(BaseModel):
    """Analytics response"""
    period_days: int
    total_queries: int
    total_feedback: int
    average_rating: float
    rating_distribution: Dict[str, int]
    events: List[Dict[str, Any]]
    top_topics: List[Dict[str, Any]]


# ========== Health Schema ==========

class HealthResponse(BaseModel):
    """Health check response"""
    status: str
    version: str
    timestamp: datetime
    services: Dict[str, bool]


# ========== Guardrails Schemas ==========

class GuardrailCheck(BaseModel):
    """Result of guardrail check"""
    allowed: bool
    reason: Optional[str] = None
    category: Optional[str] = None


































































    8. backend/services/__init__.py:
9. backend/services/embeddings.py:
"""
Embedding service using SentenceTransformers
"""
from sentence_transformers import SentenceTransformer
import numpy as np
from typing import List, Union
import logging

from core.config import settings

logger = logging.getLogger(__name__)


class EmbeddingService:
    """Manages text embeddings for RAG"""
    
    def __init__(self):
        self.model_name = settings.EMBEDDING_MODEL
        self.model = None
        self.dimension = settings.EMBEDDING_DIM
    
    async def initialize(self):
        """Load embedding model"""
        logger.info(f"Loading embedding model: {self.model_name}")
        self.model = SentenceTransformer(self.model_name)
        logger.info(f"✅ Embedding model loaded (dim: {self.dimension})")
    
    def encode(
        self,
        texts: Union[str, List[str]],
        batch_size: int = 32,
        show_progress: bool = False
    ) -> np.ndarray:
        """
        Encode text(s) into embeddings
        
        Args:
            texts: Single text or list of texts
            batch_size: Batch size for encoding
            show_progress: Show progress bar
            
        Returns:
            numpy array of embeddings
        """
        if not self.model:
            raise RuntimeError("Model not initialized. Call initialize() first.")
        
        # Convert single text to list
        is_single = isinstance(texts, str)
        if is_single:
            texts = [texts]
        
        # Encode
        embeddings = self.model.encode(
            texts,
            batch_size=batch_size,
            show_progress_bar=show_progress,
            convert_to_numpy=True
        )
        
        # Return single embedding if input was single text
        if is_single:
            return embeddings[0]
        
        return embeddings
    
    def similarity(
        self,
        embedding1: np.ndarray,
        embedding2: np.ndarray
    ) -> float:
        """
        Calculate cosine similarity between two embeddings
        
        Args:
            embedding1: First embedding vector
            embedding2: Second embedding vector
            
        Returns:
            Cosine similarity score (0-1)
        """
        # Normalize vectors
        norm1 = np.linalg.norm(embedding1)
        norm2 = np.linalg.norm(embedding2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        # Cosine similarity
        similarity = np.dot(embedding1, embedding2) / (norm1 * norm2)
        
        # Clip to [0, 1] range
        return float(np.clip(similarity, 0, 1))
    
    def batch_similarity(
        self,
        query_embedding: np.ndarray,
        embeddings: np.ndarray
    ) -> np.ndarray:
        """
        Calculate similarity between query and multiple embeddings
        
        Args:
            query_embedding: Query embedding vector
            embeddings: Array of embedding vectors
            
        Returns:
            Array of similarity scores
        """
        # Normalize query
        query_norm = query_embedding / np.linalg.norm(query_embedding)
        
        # Normalize all embeddings
        norms = np.linalg.norm(embeddings, axis=1, keepdims=True)
        embeddings_norm = embeddings / np.maximum(norms, 1e-10)
        
        # Calculate similarities
        similarities = np.dot(embeddings_norm, query_norm)
        
        return np.clip(similarities, 0, 1)
10. backend/services/gemini_aent.py
11. backend/services/guardrails.py
12. backend/service/rag_engine.py
13. backend/services/routing:
"""
Intelligent routing between knowledge base and web search
"""
from typing import Dict
import logging

from core.schemas import ChatRequest, ChatResponse, RoutingDecision, SourceType
from services.rag_engine import RAGEngine
from services.web_search import WebSearchService
from services.gemini_agent import GeminiAgent
from services.guardrails import GuardrailsSystem

logger = logging.getLogger(__name__)


class RoutingService:
    """Routes queries to appropriate source and generates responses"""
    
    def __init__(
        self,
        rag_engine: RAGEngine,
        web_search: WebSearchService,
        gemini_agent: GeminiAgent,
        guardrails: GuardrailsSystem
    ):
        self.rag_engine = rag_engine
        self.web_search = web_search
        self.gemini_agent = gemini_agent
        self.guardrails = guardrails
    
    async def process_query(self, request: ChatRequest) -> ChatResponse:
        """
        Process user query with intelligent routing
        
        Args:
            request: ChatRequest with user's message
            
        Returns:
            ChatResponse with solution
        """
        query = request.message
        
        # Step 1: Input Guardrails
        guardrail_check = self.guardrails.check_input_guardrail(query)
        
        if not guardrail_check.allowed:
            logger.warning(f"Query blocked: {guardrail_check.reason}")
            return ChatResponse(
                success=False,
                message=guardrail_check.reason,
                query=query,
                solution=None,
                blocked=True,
                error=guardrail_check.reason
            )
        
        # Step 2: Sanitize input
        query = self.guardrails.sanitize_input(query)
        
        # Step 3: Routing Decision
        routing_decision = self.rag_engine.should_use_knowledge_base(query)
        
        logger.info(f"Routing: {routing_decision['source']} (confidence: {routing_decision['confidence']:.3f})")
        
        # Step 4: Generate solution based on routing
        if routing_decision['use_kb']:
            # Use knowledge base
            result = await self._generate_from_kb(query, routing_decision['best_match'])
        else:
            # Use web search
            result = await self._generate_from_web(query)
        
        # Step 5: Output Guardrails
        if result['success']:
            output_check = self.guardrails.check_output_guardrail(result['solution'])
            if not output_check.allowed:
                logger.warning("Response blocked by output guardrails")
                return ChatResponse(
                    success=False,
                    message="Generated response did not pass safety checks",
                    query=query,
                    solution=None,
                    blocked=True,
                    error="Output validation failed"
                )
        
        # Step 6: Build response
        routing_info = RoutingDecision(
            use_kb=routing_decision['use_kb'],
            confidence=routing_decision['confidence'],
            reason=routing_decision['reason'],
            source=SourceType(routing_decision['source'])
        )
        
        if result['success']:
            return ChatResponse(
                success=True,
                message="Solution generated successfully",
                query=query,
                solution=result['solution'],
                routing=routing_info,
                metadata={
                    'model': result.get('model', 'unknown'),
                    'source': routing_decision['source'],
                    'confidence': routing_decision['confidence']
                },
                blocked=False
            )
        else:
            return ChatResponse(
                success=False,
                message="Failed to generate solution",
                query=query,
                solution=None,
                routing=routing_info,
                error=result.get('error', 'Unknown error'),
                blocked=False
            )
    
    async def _generate_from_kb(self, query: str, kb_item: Dict) -> Dict:
        """Generate solution using knowledge base"""
        logger.info(f"Generating from KB: {kb_item['question'][:50]}...")
        
        try:
            result = self.gemini_agent.generate_with_kb(query, kb_item)
            return result
        except Exception as e:
            logger.error(f"KB generation failed: {e}")
            return {
                'success': False,
                'solution': None,
                'error': str(e)
            }
    
    async def _generate_from_web(self, query: str) -> Dict:
        """Generate solution using web search"""
        logger.info(f"Generating from web search...")
        
        try:
            # Perform web search
            search_result = self.web_search.search_with_retry(query)
            
            if not search_result.success:
                # Fallback to direct LLM
                logger.warning("Web search failed, using direct LLM")
                return self.gemini_agent.generate_solution(query)
            
            # Extract context
            context = self.web_search.extract_context(search_result)
            
            # Generate solution with context
            result = self.gemini_agent.generate_with_web(query, context)
            
            return result
            
        except Exception as e:
            logger.error(f"Web generation failed: {e}")
            # Fallback to direct LLM
            return self.gemini_agent.generate_solution(query)






































            14. backend/services/web_search.py
15.backend/utilis/__init__.py
16.backend/utilis/helper.py
17.backend/__init__py:
# backend/__init__.py
"""MathAI Backend Package"""
__version__ = "1.0.0"

# backend/core/__init__.py
"""Core modules for configuration and database"""

# backend/services/__init__.py
"""Business logic services"""

# backend/api/__init__.py
"""API routes and endpoints"""

# backend/utils/__init__.py
"""Utility functions"""18.backend/
19.backend/main.py:
"""
MathAI Backend - FastAPI Application Entry Point
"""
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import logging
from contextlib import asynccontextmanager

from core.config import settings
from core.database import init_db
from api.routes import router
from services.rag_engine import RAGEngine
from services.embeddings import EmbeddingService

# Configure logging
logging.basicConfig(
    level=getattr(logging, settings.LOG_LEVEL),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# Global instances (initialized on startup)
rag_engine = None
embedding_service = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Startup and shutdown events"""
    global rag_engine, embedding_service
    
    # Startup
    logger.info("🚀 Starting MathAI Backend...")
    
    try:
        # Initialize database
        init_db()
        logger.info("✅ Database initialized")
        
        # Initialize embedding service
        embedding_service = EmbeddingService()
        await embedding_service.initialize()
        logger.info("✅ Embedding service initialized")
        
        # Initialize RAG engine
        rag_engine = RAGEngine(embedding_service)
        await rag_engine.initialize()
        logger.info("✅ RAG engine initialized")
        
        logger.info("✅ MathAI Backend ready!")
        
    except Exception as e:
        logger.error(f"❌ Startup failed: {e}")
        raise
    
    yield
    
    # Shutdown
    logger.info("👋 Shutting down MathAI Backend...")


# Create FastAPI app
app = FastAPI(
    title="MathAI API",
    description="Intelligent Math Problem Solver with RAG and Web Search",
    version="1.0.0",
    lifespan=lifespan
)


# CORS Configuration
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# Include API routes
app.include_router(router, prefix="/api")


# Root endpoint
@app.get("/")
async def root():
    """Health check and API info"""
    return {
        "name": "MathAI API",
        "version": "1.0.0",
        "status": "running",
        "docs": "/docs",
        "health": "/api/health"
    }


# Global error handler
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    """Handle all uncaught exceptions"""
    logger.error(f"Unhandled exception: {exc}", exc_info=True)
    
    return JSONResponse(
        status_code=500,
        content={
            "success": False,
            "error": "Internal server error",
            "message": str(exc) if settings.DEBUG_MODE else "An error occurred"
        }
    )


# Make global instances available to routes
@app.middleware("http")
async def add_global_instances(request: Request, call_next):
    """Add global instances to request state"""
    request.state.rag_engine = rag_engine
    request.state.embedding_service = embedding_service
    response = await call_next(request)
    return response


if __name__ == "__main__":
    import uvicorn
    
    uvicorn.run(
        "main:app",
        host=settings.BACKEND_HOST,
        port=settings.BACKEND_PORT,
        reload=settings.DEBUG_MODE,
        log_level=settings.LOG_LEVEL.lower()
    )

































    ├── data/
│   ├── 19. math_knowledge_base.json  
[
  {
    "question": "How do I solve a quadratic equation?",
    "answer": "To solve a quadratic equation ax² + bx + c = 0:\n\n1. Identify coefficients a, b, and c\n2. Use the quadratic formula: x = (-b ± √(b²-4ac)) / 2a\n3. Calculate the discriminant: Δ = b²-4ac\n   - If Δ > 0: two real solutions\n   - If Δ = 0: one real solution\n   - If Δ < 0: two complex solutions\n4. Substitute values and solve\n\nExample: x² + 5x + 6 = 0\na=1, b=5, c=6\nx = (-5 ± √(25-24)) / 2 = (-5 ± 1) / 2\nx = -2 or x = -3",
    "topic": "Algebra",
    "difficulty": "Medium"
  },
  {
    "question": "What is the Pythagorean theorem?",
    "answer": "The Pythagorean theorem states that in a right triangle, the square of the hypotenuse (longest side) equals the sum of squares of the other two sides.\n\nFormula: a² + b² = c²\n\nWhere:\n- a and b are the lengths of the legs\n- c is the length of the hypotenuse\n\nExample: If a=3 and b=4, then:\nc² = 3² + 4² = 9 + 16 = 25\nc = 5",
    "topic": "Geometry",
    "difficulty": "Easy"
  },
  {
    "question": "How do I find the derivative of a function?",
    "answer": "To find the derivative of a function:\n\n1. Basic power rule: d/dx(xⁿ) = n·xⁿ⁻¹\n2. Constant rule: d/dx(c) = 0\n3. Sum rule: d/dx(f+g) = f' + g'\n4. Product rule: d/dx(fg) = f'g + fg'\n5. Chain rule: d/dx(f(g(x))) = f'(g(x))·g'(x)\n\nExample: f(x) = 3x² + 2x - 1\nf'(x) = 6x + 2",
    "topic": "Calculus",
    "difficulty": "Medium"
  },
  {
    "question": "How do I calculate the area of a circle?",
    "answer": "To calculate the area of a circle:\n\nFormula: A = πr²\n\nWhere:\n- A is the area\n- π ≈ 3.14159\n- r is the radius\n\nExample: Circle with radius 5 cm\nA = π × 5² = π × 25 ≈ 78.54 cm²\n\nNote: If you know the diameter d, use r = d/2",
    "topic": "Geometry",
    "difficulty": "Easy"
  },
  {
    "question": "What is the quadratic formula?",
    "answer": "The quadratic formula solves equations of the form ax² + bx + c = 0:\n\nx = (-b ± √(b²-4ac)) / 2a\n\nSteps:\n1. Identify a, b, c from your equation\n2. Calculate discriminant: Δ = b²-4ac\n3. Substitute into formula\n4. Simplify\n\nThe ± means you'll get two solutions.",
    "topic": "Algebra",
    "difficulty": "Medium"
  },
  {
    "question": "How do I factor a quadratic expression?",
    "answer": "To factor x² + bx + c:\n\n1. Find two numbers that:\n   - Multiply to give c\n   - Add to give b\n2. Write as (x + p)(x + q)\n\nExample: x² + 5x + 6\n- Need numbers that multiply to 6 and add to 5\n- 2 × 3 = 6 and 2 + 3 = 5\n- Answer: (x + 2)(x + 3)",
    "topic": "Algebra",
    "difficulty": "Medium"
  },
  {
    "question": "How do I calculate the volume of a sphere?",
    "answer": "To calculate the volume of a sphere:\n\nFormula: V = (4/3)πr³\n\nWhere:\n- V is volume\n- π ≈ 3.14159\n- r is radius\n\nExample: Sphere with radius 3 cm\nV = (4/3) × π × 3³\nV = (4/3) × π × 27\nV ≈ 113.10 cm³",
    "topic": "Geometry",
    "difficulty": "Medium"
  },
  {
    "question": "What is the slope-intercept form of a line?",
    "answer": "The slope-intercept form is: y = mx + b\n\nWhere:\n- m is the slope (rise/run)\n- b is the y-intercept (where line crosses y-axis)\n\nExample: y = 2x + 3\n- Slope = 2 (goes up 2 for every 1 right)\n- Y-intercept = 3 (crosses y-axis at (0,3))\n\nTo graph:\n1. Plot y-intercept\n2. Use slope to find next point\n3. Draw line through points",
    "topic": "Algebra",
    "difficulty": "Easy"
  },
  {
    "question": "How do I find the integral of a function?",
    "answer": "To find the integral (antiderivative):\n\nBasic rules:\n1. Power rule: ∫xⁿ dx = xⁿ⁺¹/(n+1) + C\n2. Constant rule: ∫c dx = cx + C\n3. Sum rule: ∫(f+g) dx = ∫f dx + ∫g dx\n\nExample: ∫(3x² + 2x) dx\n= 3(x³/3) + 2(x²/2) + C\n= x³ + x² + C\n\nNote: Always add constant C for indefinite integrals",
    "topic": "Calculus",
    "difficulty": "Medium"
  },
  {
    "question": "How do I solve a system of linear equations?",
    "answer": "Methods to solve system of equations:\n\n**Substitution Method:**\n1. Solve one equation for one variable\n2. Substitute into other equation\n3. Solve for remaining variable\n4. Back-substitute to find first variable\n\n**Elimination Method:**\n1. Multiply equations to make coefficients opposite\n2. Add equations to eliminate a variable\n3. Solve for remaining variable\n4. Substitute back\n\nExample: \nx + y = 5\nx - y = 1\nAdd: 2x = 6, so x = 3\nSubstitute: 3 + y = 5, so y = 2\nSolution: (3, 2)",
    "topic": "Algebra",
    "difficulty": "Medium"
  }
]
│   ├── 20. rag_config.json           # From Notebook 2
│   ├── 21. mcp_config.json           # From Notebook 3
│   └── 22. feedback.db

├── notebooks/                    # Keep your original notebooks for reference
│   ├── 01_data_preparation.ipynb
│   ├── 02_rag_qdrant.ipynb
│   ├── 03_mcp_websearch.ipynb
│   ├── 04_routing_agent.ipynb
│   └── 05_gradio_ui.ipynb

├── README.md
# MathAI - Intelligent Math Problem Solver

A full-stack AI-powered math tutor with RAG (Retrieval-Augmented Generation), web search, and human-in-the-loop feedback.

## Features

- 🧮 **Step-by-step Math Solutions** - Clear explanations for algebra, calculus, geometry, and more
- 🔍 **Smart Routing** - Uses knowledge base first, falls back to web search
- 🛡️ **Guardrails** - Input/output validation for safety
- 💬 **Feedback Learning** - Improves from user corrections
- 📊 **Analytics Dashboard** - Track performance and usage
- 🎨 **Modern UI** - ChatGPT-style interface

## Tech Stack

**Backend:**
- FastAPI (Python 3.9+)
- Qdrant Vector Database
- Google Gemini 1.5 Flash (FREE)
- Tavily Web Search API
- SentenceTransformers for embeddings
- SQLite for feedback storage

**Frontend:**
- React 18
- Vite
- Tailwind CSS
- Lucide Icons

## Quick Start

### Prerequisites

```bash
# Required
Python 3.9+
Node.js 18+
npm or yarn

# API Keys (both FREE)
Google Gemini API: https://aistudio.google.com/apikey
Tavily API: https://tavily.com
```

### Installation

1. **Clone the repository**
```bash
git clone <your-repo>
cd MathAI
```

2. **Set up environment variables**
```bash
cp .env.example .env
# Edit .env and add your API keys:
# GEMINI_API_KEY=your_key_here
# TAVILY_API_KEY=your_key_here
```

3. **Install backend dependencies**
```bash
pip install -r requirements.txt
```

4. **Install frontend dependencies**
```bash
cd frontend
npm install
cd ..
```

5. **Initialize database and load knowledge base**
```bash
python scripts/init_db.py
python scripts/load_data.py
```

6. **Start development servers**
```bash
# Option 1: Use convenience script
bash scripts/dev.sh

# Option 2: Manual (2 terminals)
# Terminal 1 - Backend
cd backend
uvicorn main:app --reload --port 8000

# Terminal 2 - Frontend
cd frontend
npm run dev
```

7. **Open browser**
```
Frontend: http://localhost:5173
Backend API: http://localhost:8000
API Docs: http://localhost:8000/docs
```

## Project Structure

```
MathAI/
├── backend/          # FastAPI backend
│   ├── api/         # API routes
│   ├── core/        # Config & database
│   ├── services/    # Business logic
│   └── utils/       # Helpers
├── frontend/         # React frontend
│   └── src/
│       ├── components/
│       ├── hooks/
│       └── services/
├── data/            # Knowledge base & configs
├── notebooks/       # Original Jupyter notebooks
└── scripts/         # Utility scripts
```

## API Endpoints

### Chat
- `POST /api/chat` - Send math question, get solution
- `GET /api/chat/history` - Get chat history

### Feedback
- `POST /api/feedback` - Submit feedback for a solution
- `GET /api/feedback/stats` - Get analytics

### System
- `GET /api/health` - Health check
- `GET /api/kb/search` - Search knowledge base directly

## Configuration

Edit `.env` file:

```env
# Required
GEMINI_API_KEY=your_gemini_key
TAVILY_API_KEY=your_tavily_key

# Optional
DATABASE_URL=sqlite:///./data/feedback.db
QDRANT_MEMORY=true
LOG_LEVEL=INFO
CORS_ORIGINS=http://localhost:5173
```

## Usage Examples

### Sample Questions

```
✅ Good questions:
- "Solve for x: 2x + 5 = 13"
- "Find the derivative of 3x² + 2x - 1"
- "What is the area of a circle with radius 5 cm?"
- "Prove the Pythagorean theorem"

❌ Will be blocked:
- "What's the weather today?" (not math)
- "How to hack a website?" (inappropriate)
```

### Feedback System

1. Ask a question
2. Review the solution
3. Click feedback buttons (👍/👎)
4. Optionally provide:
   - Rating (1-5 stars)
   - Comments
   - Improved solution

The system learns from your feedback!

## Development

### Run tests
```bash
# Backend
pytest backend/tests/

# Frontend
cd frontend
npm test
```

### Code formatting
```bash
# Backend
black backend/
isort backend/

# Frontend
cd frontend
npm run lint
```

### Build for production
```bash
# Backend
docker build -f docker/Dockerfile.backend -t mathai-backend .

# Frontend
cd frontend
npm run build
```

## Docker Deployment

```bash
# Start all services
docker-compose up -d

# Stop services
docker-compose down

# View logs
docker-compose logs -f
```

## Troubleshooting

### "API key not configured"
- Make sure `.env` file exists in project root
- Check that `GEMINI_API_KEY` is set correctly
- Restart backend server

### "Knowledge base not found"
- Run `python scripts/load_data.py`
- Check that `data/math_knowledge_base.json` exists

### "Port already in use"
- Backend: Change port in `backend/main.py`
- Frontend: Set `PORT=3000` in `frontend/.env`

## Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## License

MIT License - see LICENSE file

## Acknowledgments

- Google Gemini for free LLM API
- Tavily for web search
- Qdrant for vector database
- SentenceTransformers for embeddings

## Support

- 📧 Email: brijeshkpurohit04@gmail.com
- 🐛 Issues: [GitHub Issues](your-repo/issues)
- 📖 Docs: [Full Documentation](your-docs-link)

---

Built with ❤️ for students and educators
├── .env                          # API keys (GEMINI_API_KEY, TAVILY_API_KEY)
# ============================================================
# MathAI Environment Configuration
# ============================================================
# Copy this file to .env and fill in your API keys

# ============================================================
# REQUIRED: AI APIs (Both FREE)
# ============================================================

# Google Gemini API (FREE)
# Get key: https://aistudio.google.com/apikey
GEMINI_API_KEY=AIzaSyAIPq-xh7V5_oGF5khHC0k8q-jqsGNfhyc

# Tavily Web Search API (FREE)
# Get key: https://tavily.com
TAVILY_API_KEY=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

# ============================================================
# DATABASE
# ============================================================
DATABASE_URL=sqlite:///./data/feedback.db

# ============================================================
# QDRANT VECTOR DATABASE
# ============================================================
# Use in-memory for development
QDRANT_MEMORY=true
# For production, use persistent storage:
# QDRANT_MEMORY=false
# QDRANT_PATH=./data/qdrant_storage

# ============================================================
# EMBEDDING MODEL
# ============================================================
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DIM=384

# ============================================================
# RAG CONFIGURATION
# ============================================================
# Minimum similarity score to use knowledge base (0.0-1.0)
KB_CONFIDENCE_THRESHOLD=0.5
# Number of similar questions to retrieve
KB_TOP_K=3
# Maximum web search results
WEB_SEARCH_MAX_RESULTS=3

# ============================================================
# SERVER CONFIGURATION
# ============================================================
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
FRONTEND_PORT=5173

# CORS allowed origins (comma-separated)
CORS_ORIGINS=http://localhost:5173,http://localhost:3000

# ============================================================
# LOGGING
# ============================================================
LOG_LEVEL=INFO
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL

# ============================================================
# SECURITY
# ============================================================
# Secret key for session management (generate with: openssl rand -hex 32)
SECRET_KEY=your_secret_key_here_generate_with_openssl

# ============================================================
# GUARDRAILS
# ============================================================
# Enable input/output validation
ENABLE_GUARDRAILS=true
# Maximum query length
MAX_QUERY_LENGTH=500

# ============================================================
# FEEDBACK LEARNING
# ============================================================
# Enable feedback-based improvements
ENABLE_FEEDBACK_LEARNING=true
# Minimum rating to consider feedback positive (1-5)
MIN_POSITIVE_RATING=4

# ============================================================
# RATE LIMITING
# ============================================================
RATE_LIMIT_ENABLED=true
RATE_LIMIT_PER_MINUTE=30

# ============================================================
# DEVELOPMENT
# ============================================================
DEBUG_MODE=false
# Enable detailed error messages
SHOW_STACK_TRACES=false

├── .gitignore
├── requirements.txt              # Backend Python dependencies
├── package.json                  # Frontend npm dependencies
























frontend/
│   ├── public/
│   │   ├── index.html
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="description" content="MathAI - Intelligent Math Problem Solver with AI" />
    <title>MathAI - Intelligent Math Tutor</title>
    
    <!-- Inter Font -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    
    <style>
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      
      body {
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
        -webkit-font-smoothing: antialiased;
        -moz-osx-font-smoothing: grayscale;
      }
      
      #root {
        width: 100%;
        height: 100vh;
        overflow: hidden;
      }
      
      /* Loading spinner */
      .loading-spinner {
        display: inline-block;
        width: 20px;
        height: 20px;
        border: 3px solid rgba(255, 255, 255, 0.3);
        border-radius: 50%;
        border-top-color: white;
        animation: spin 1s ease-in-out infinite;
      }
      
      @keyframes spin {
        to { transform: rotate(360deg); }
      }
    </style>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.jsx"></script>
  </body>
</html>

│   │   └── favicon.ico

│   ├── src/
│   │   ├── components/
│   │   │   ├── ChatWindow.jsx    # Main chat interface
│   │   │   ├── Sidebar.jsx       # Navigation sidebar
│   │   │   ├── MessageBubble.jsx # Individual message component
│   │   │   ├── InputArea.jsx     # Message input box
│   │   │   ├── FeedbackModal.jsx # Feedback collection
│   │   │   ├── AnalyticsView.jsx # Statistics dashboard
│   │   │   ├── AboutView.jsx     # About page
│   │   │   └── SettingsPanel.jsx # Settings modal
│   │   │
│   │   ├── hooks/
│   │   │   └── useChat.js        # Custom hook for chat logic
│   │   │
│   │   ├── services/
│   │   │   └── api.js            # Axios/fetch API client
/**
 * API Service for MathAI
 */
import axios from 'axios';

const API_BASE_URL = import.meta.env.VITE_API_URL || 'http://localhost:8000/api';

const api = axios.create({
  baseURL: API_BASE_URL,
  timeout: 30000,
  headers: {
    'Content-Type': 'application/json'
  }
});

// Request interceptor
api.interceptors.request.use(
  (config) => {
    // Add session ID if exists
    const sessionId = localStorage.getItem('session_id');
    if (sessionId) {
      config.headers['X-Session-ID'] = sessionId;
    }
    return config;
  },
  (error) => Promise.reject(error)
);

// Response interceptor
api.interceptors.response.use(
  (response) => response.data,
  (error) => {
    console.error('API Error:', error);
    return Promise.reject(error);
  }
);

export const apiService = {
  // ========== Health ==========
  health: () => api.get('/health'),

  // ========== Chat ==========
  chat: (message, sessionId = null, useFeedbackLearning = true) => 
    api.post('/chat', {
      message,
      session_id: sessionId,
      use_feedback_learning: useFeedbackLearning
    }),

  getChatHistory: (sessionId, limit = 50) =>
    api.get('/chat/history', { params: { session_id: sessionId, limit } }),

  // ========== Feedback ==========
  submitFeedback: (data) => api.post('/feedback', data),

  getFeedbackStats: () => api.get('/feedback/stats'),

  getPositiveFeedback: (minRating = 4) =>
    api.get('/feedback/positive', { params: { min_rating: minRating } }),

  // ========== Knowledge Base ==========
  searchKB: (query, topK = 3, scoreThreshold = 0.5) =>
    api.post('/kb/search', {
      query,
      top_k: topK,
      score_threshold: scoreThreshold
    }),

  getKBStats: () => api.get('/kb/stats'),

  // ========== Web Search ==========
  webSearch: (query) => api.post('/web/search', { query }),

  // ========== Analytics ==========
  getAnalytics: (days = 7) =>
    api.get('/analytics', { params: { days } }),

  // ========== Utility ==========
  improveSolution: (query, solution, feedback, improvedSuggestion = null) =>
    api.post('/improve', {
      query,
      solution,
      feedback,
      improved_suggestion: improvedSuggestion
    })
};

export default apiService;

│   │   │
│   │   ├── styles/
│   │   │   ├── globals.css
│   │   │   └── components.css
│   │   │
│   │   ├── App.jsx
import React, { useState, useRef, useEffect } from 'react';
import { Settings, Plus, Send, Mic, ThumbsUp, ThumbsDown, Copy, MoreHorizontal, Menu, Share2, BarChart3, Info, User, X } from 'lucide-react';

const API_URL = 'http://localhost:8000/api';

// API Service
const api = {
  chat: async (message, sessionId) => {
    const res = await fetch(`${API_URL}/chat`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ message, session_id: sessionId, use_feedback_learning: true })
    });
    return res.json();
  },
  submitFeedback: async (data) => {
    const res = await fetch(`${API_URL}/feedback`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(data)
    });
    return res.json();
  },
  getStats: async () => {
    const res = await fetch(`${API_URL}/feedback/stats`);
    return res.json();
  }
};

export default function MathAI() {
  const [messages, setMessages] = useState([]);
  const [inputValue, setInputValue] = useState('');
  const [loading, setLoading] = useState(false);
  const [showSidebar, setShowSidebar] = useState(true);
  const [currentTab, setCurrentTab] = useState('chat');
  const [sessionId] = useState(() => `session_${Date.now()}`);
  const [feedbackMode, setFeedbackMode] = useState(false);
  const [selectedMessage, setSelectedMessage] = useState(null);
  const [rating, setRating] = useState(3);
  const [comment, setComment] = useState('');
  const [stats, setStats] = useState({ total_feedback: 0, average_rating: 0 });
  const messagesEndRef = useRef(null);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  useEffect(() => {
    api.getStats().then(setStats).catch(console.error);
  }, []);

  const handleSend = async () => {
    if (!inputValue.trim() || loading) return;

    const userMessage = {
      id: Date.now(),
      role: 'user',
      content: inputValue,
      timestamp: new Date().toLocaleTimeString()
    };

    setMessages(prev => [...prev, userMessage]);
    setInputValue('');
    setLoading(true);

    try {
      const response = await api.chat(inputValue, sessionId);
      
      const aiMessage = {
        id: Date.now() + 1,
        role: 'assistant',
        content: response.solution || response.message,
        timestamp: new Date().toLocaleTimeString(),
        metadata: response.metadata,
        blocked: response.blocked
      };

      setMessages(prev => [...prev, aiMessage]);
    } catch (error) {
      const errorMessage = {
        id: Date.now() + 1,
        role: 'assistant',
        content: '❌ Error: Could not generate solution. Please check if the backend is running.',
        timestamp: new Date().toLocaleTimeString(),
        blocked: false
      };
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setLoading(false);
    }
  };

  const handleFeedback = (message, action) => {
    if (action === 'feedback') {
      setSelectedMessage(message);
      setFeedbackMode(true);
    }
  };

  const submitFeedback = async () => {
    if (!selectedMessage) return;

    try {
      const prevUserMessage = messages[messages.indexOf(selectedMessage) - 1];
      
      await api.submitFeedback({
        query: prevUserMessage.content,
        solution: selectedMessage.content,
        rating,
        comment: comment || null
      });

      alert('✅ Feedback submitted! Thank you for helping us improve.');
      setFeedbackMode(false);
      setSelectedMessage(null);
      setRating(3);
      setComment('');
      
      // Refresh stats
      api.getStats().then(setStats).catch(console.error);
    } catch (error) {
      alert('❌ Failed to submit feedback');
    }
  };

  const StatisticsView = () => (
    <div className="p-6 max-w-4xl mx-auto">
      <h2 className="text-2xl font-semibold text-gray-100 mb-6">📊 Performance Analytics</h2>
      
      <div className="grid grid-cols-1 md:grid-cols-3 gap-4 mb-8">
        <div className="bg-gray-800 rounded-lg p-6 border border-gray-700">
          <div className="text-gray-400 text-sm mb-2">Total Queries</div>
          <div className="text-3xl font-bold text-gray-100">{messages.filter(m => m.role === 'user').length}</div>
        </div>
        <div className="bg-gray-800 rounded-lg p-6 border border-gray-700">
          <div className="text-gray-400 text-sm mb-2">Average Rating</div>
          <div className="text-3xl font-bold text-gray-100">{stats.average_rating.toFixed(1)}/5</div>
        </div>
        <div className="bg-gray-800 rounded-lg p-6 border border-gray-700">
          <div className="text-gray-400 text-sm mb-2">Total Feedback</div>
          <div className="text-3xl font-bold text-gray-100">{stats.total_feedback}</div>
        </div>
      </div>
    </div>
  );

  const AboutView = () => (
    <div className="p-6 max-w-4xl mx-auto">
      <h2 className="text-2xl font-semibold text-gray-100 mb-6">ℹ️ About MathAI</h2>
      
      <div className="bg-gray-800 rounded-lg p-6 border border-gray-700 mb-6">
        <h3 className="text-lg font-semibold text-gray-100 mb-3">Features</h3>
        <ul className="space-y-2 text-gray-300">
          <li>✅ Smart routing: Knowledge Base → Web Search → LLM</li>
          <li>✅ Input/Output guardrails for safety</li>
          <li>✅ Human-in-the-loop feedback</li>
          <li>✅ Continuous learning from feedback</li>
          <li>✅ FREE Gemini 1.5 Flash API</li>
        </ul>
      </div>

      <div className="bg-gray-800 rounded-lg p-6 border border-gray-700">
        <h3 className="text-lg font-semibold text-gray-100 mb-3">Sample Questions</h3>
        <ul className="space-y-2 text-gray-300">
          <li>• "Solve for x: 2x + 5 = 13"</li>
          <li>• "Find the derivative of x²"</li>
          <li>• "Calculate the area of a circle with radius 5"</li>
          <li>• "What is the Pythagorean theorem?"</li>
        </ul>
      </div>
    </div>
  );

  return (
    <div className="flex h-screen bg-gray-950 text-white">
      {/* Sidebar */}
      <div className={`${showSidebar ? 'w-64' : 'w-0'} bg-gray-900 border-r border-gray-800 transition-all duration-300 overflow-hidden flex flex-col`}>
        <div className="p-4 border-b border-gray-800">
          <button 
            onClick={() => {
              setMessages([]);
              setCurrentTab('chat');
            }}
            className="w-full flex items-center gap-3 px-4 py-3 rounded-lg bg-gray-800 hover:bg-gray-750 transition-colors"
          >
            <Plus size={18} />
            <span className="font-medium">New Chat</span>
          </button>
        </div>

        <div className="flex-1 overflow-y-auto p-3">
          <div className="space-y-1">
            {messages.filter(m => m.role === 'user').slice(-10).reverse().map((msg, idx) => (
              <button
                key={idx}
                className="w-full text-left px-3 py-2 rounded-lg hover:bg-gray-800 transition-colors text-sm text-gray-300 truncate"
              >
                {msg.content}
              </button>
            ))}
          </div>
        </div>

        <div className="border-t border-gray-800 p-3 space-y-1">
          <button 
            onClick={() => setCurrentTab('stats')}
            className="w-full flex items-center gap-3 px-3 py-2 rounded-lg hover:bg-gray-800 transition-colors text-sm"
          >
            <BarChart3 size={18} />
            <span>Analytics</span>
          </button>
          <button 
            onClick={() => setCurrentTab('about')}
            className="w-full flex items-center gap-3 px-3 py-2 rounded-lg hover:bg-gray-800 transition-colors text-sm"
          >
            <Info size={18} />
            <span>About</span>
          </button>
        </div>
      </div>

      {/* Main Content */}
      <div className="flex-1 flex flex-col">
        {/* Header */}
        <div className="h-14 border-b border-gray-800 flex items-center justify-between px-4">
          <div className="flex items-center gap-3">
            <button 
              onClick={() => setShowSidebar(!showSidebar)}
              className="p-2 hover:bg-gray-800 rounded-lg transition-colors"
            >
              <Menu size={20} />
            </button>
            <h1 className="text-lg font-semibold">🧮 MathAI</h1>
          </div>
        </div>

        {/* Messages Area */}
        <div className="flex-1 overflow-y-auto">
          {currentTab === 'chat' && (
            <>
              {messages.length === 0 ? (
                <div className="h-full flex flex-col items-center justify-center px-4">
                  <h2 className="text-4xl font-semibold mb-8 text-center">What can I help with?</h2>
                  <div className="grid grid-cols-1 md:grid-cols-2 gap-3 w-full max-w-2xl">
                    {[
                      "Solve for x: 2x + 5 = 13",
                      "Find the derivative of x²",
                      "Calculate area of circle r=5",
                      "What is the Pythagorean theorem?"
                    ].map((example, idx) => (
                      <button
                        key={idx}
                        onClick={() => setInputValue(example)}
                        className="p-4 bg-gray-800 hover:bg-gray-750 rounded-xl text-left transition-colors border border-gray-700"
                      >
                        <div className="text-sm text-gray-300">{example}</div>
                      </button>
                    ))}
                  </div>
                </div>
              ) : (
                <div className="max-w-3xl mx-auto px-4 py-6 space-y-6">
                  {messages.map((message) => (
                    <div key={message.id} className={`${message.role === 'user' ? 'ml-auto max-w-xl' : 'mr-auto'}`}>
                      <div className={`${message.role === 'user' ? 'bg-blue-600 text-white' : 'bg-gray-800 text-gray-100'} rounded-2xl px-4 py-3`}>
                        <div className="text-sm whitespace-pre-wrap">{message.content}</div>
                      </div>
                      
                      {message.role === 'assistant' && !message.blocked && (
                        <div className="flex items-center gap-2 mt-2 ml-2">
                          <button 
                            onClick={() => navigator.clipboard.writeText(message.content)}
                            className="p-2 hover:bg-gray-800 rounded-lg transition-colors"
                            title="Copy"
                          >
                            <Copy size={16} className="text-gray-400" />
                          </button>
                          <button 
                            onClick={() => handleFeedback(message, 'feedback')}
                            className="p-2 hover:bg-gray-800 rounded-lg transition-colors"
                            title="Give Feedback"
                          >
                            <MoreHorizontal size={16} className="text-gray-400" />
                          </button>
                        </div>
                      )}
                    </div>
                  ))}
                  {loading && (
                    <div className="mr-auto bg-gray-800 rounded-2xl px-4 py-3">
                      <div className="flex gap-1">
                        <div className="w-2 h-2 bg-gray-400 rounded-full animate-bounce" style={{animationDelay: '0s'}}></div>
                        <div className="w-2 h-2 bg-gray-400 rounded-full animate-bounce" style={{animationDelay: '0.2s'}}></div>
                        <div className="w-2 h-2 bg-gray-400 rounded-full animate-bounce" style={{animationDelay: '0.4s'}}></div>
                      </div>
                    </div>
                  )}
                  <div ref={messagesEndRef} />
                </div>
              )}
            </>
          )}

          {currentTab === 'stats' && <StatisticsView />}
          {currentTab === 'about' && <AboutView />}
        </div>

        {/* Input Area */}
        {currentTab === 'chat' && (
          <div className="border-t border-gray-800 p-4">
            <div className="max-w-3xl mx-auto">
              <div className="bg-gray-800 rounded-2xl border border-gray-700 focus-within:border-gray-600 transition-colors">
                <div className="flex items-end gap-2 p-2">
                  <textarea
                    value={inputValue}
                    onChange={(e) => setInputValue(e.target.value)}
                    onKeyDown={(e) => {
                      if (e.key === 'Enter' && !e.shiftKey) {
                        e.preventDefault();
                        handleSend();
                      }
                    }}
                    placeholder="Ask any math question..."
                    className="flex-1 bg-transparent outline-none resize-none text-gray-100 placeholder-gray-500 px-2 py-2 max-h-32"
                    rows={1}
                    disabled={loading}
                  />
                  <button 
                    onClick={handleSend}
                    disabled={!inputValue.trim() || loading}
                    className={`p-2 rounded-lg transition-colors ${inputValue.trim() && !loading ? 'bg-blue-600 hover:bg-blue-700' : 'bg-gray-700'}`}
                  >
                    <Send size={20} className={inputValue.trim() && !loading ? 'text-white' : 'text-gray-500'} />
                  </button>
                </div>
              </div>
            </div>
          </div>
        )}
      </div>

      {/* Feedback Modal */}
      {feedbackMode && (
        <div className="fixed inset-0 bg-black/50 flex items-center justify-center z-50">
          <div className="bg-gray-900 rounded-xl p-6 w-full max-w-lg border border-gray-800">
            <div className="flex items-center justify-between mb-4">
              <h3 className="text-xl font-semibold">💬 Provide Feedback</h3>
              <button onClick={() => setFeedbackMode(false)} className="p-1 hover:bg-gray-800 rounded">
                <X size={20} />
              </button>
            </div>
            <div className="space-y-4">
              <div>
                <label className="block text-sm text-gray-400 mb-2">Rate this solution (1-5)</label>
                <input 
                  type="range" 
                  min="1" 
                  max="5" 
                  value={rating}
                  onChange={(e) => setRating(parseInt(e.target.value))}
                  className="w-full" 
                />
                <div className="text-center text-2xl mt-2">{'⭐'.repeat(rating)}</div>
              </div>
              <div>
                <label className="block text-sm text-gray-400 mb-2">Comments</label>
                <textarea 
                  value={comment}
                  onChange={(e) => setComment(e.target.value)}
                  className="w-full bg-gray-800 rounded-lg px-3 py-2 border border-gray-700 outline-none focus:border-gray-600"
                  rows={3}
                  placeholder="Share your thoughts..."
                />
              </div>
              <button 
                onClick={submitFeedback}
                className="w-full bg-blue-600 hover:bg-blue-700 py-2 rounded-lg font-medium transition-colors"
              >
                📤 Submit Feedback
              </button>
            </div>
          </div>
        </div>
      )}
    </div>
  );
}

│   │   └── index.js

@tailwind base;
@tailwind components;
@tailwind utilities;

@layer base {
  * {
    @apply border-border;
  }
  
  body {
    @apply bg-gray-950 text-white;
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
  }
}

@layer components {
  .btn-primary {
    @apply bg-blue-600 hover:bg-blue-700 text-white px-4 py-2 rounded-lg transition-colors;
  }
  
  .btn-secondary {
    @apply bg-gray-800 hover:bg-gray-750 text-white px-4 py-2 rounded-lg transition-colors;
  }
  
  .input-field {
    @apply bg-gray-800 border border-gray-700 rounded-lg px-3 py-2 text-white placeholder-gray-500 focus:outline-none focus:border-gray-600 transition-colors;
  }
}

@layer utilities {
  .scrollbar-hide::-webkit-scrollbar {
    display: none;
  }
  
  .scrollbar-hide {
    -ms-overflow-style: none;
    scrollbar-width: none;
  }
}





























frontend
│   │
│   ├── package.json
{
  "name": "mathai-frontend",
  "version": "1.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview",
    "lint": "eslint . --ext js,jsx --report-unused-disable-directives --max-warnings 0"
  },
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "axios": "^1.6.2",
    "lucide-react": "^0.294.0",
    "react-markdown": "^9.0.1",
    "remark-gfm": "^4.0.0",
    "rehype-highlight": "^7.0.0"
  },
  "devDependencies": {
    "@types/react": "^18.2.43",
    "@types/react-dom": "^18.2.17",
    "@vitejs/plugin-react": "^4.2.1",
    "autoprefixer": "^10.4.16",
    "eslint": "^8.55.0",
    "eslint-plugin-react": "^7.33.2",
    "eslint-plugin-react-hooks": "^4.6.0",
    "eslint-plugin-react-refresh": "^0.4.5",
    "postcss": "^8.4.32",
    "tailwindcss": "^3.3.6",
    "vite": "^5.0.8"
  }
}
│   └── vite.config.js            # Using Vite for faster development














































